---
tags:
- movielens
- embeddings
- semantic-ids
- recommendation-systems
- movie-data
- multimodal
---

# MovieLens-32M Movies Enriched with Semantic IDs (SIDs)

This dataset is an enriched version of the MovieLens-32M dataset, specifically designed for research and development in recommendation systems, semantic search, and content understanding. It combines detailed movie metadata with high-dimensional embeddings and discrete Semantic IDs (SIDs) generated by a Residual Quantized Variational Autoencoder (RQ-VAE).

## Dataset Content

Each entry in the dataset represents a movie and includes the following fields:

*   **`movie_id`**: Unique identifier for the movie (integer).
*   **`title`**: The title of the movie (string).
*   **`genres`**: A list of genres associated with the movie (list of strings).
*   **`plot_summary`**: A detailed summary of the movie's plot (string).
*   **`director`**: The director(s) of the movie (string).
*   **`stars`**: A list of prominent actors/actresses in the movie (list of strings).
*   **`all_mpnet_base_v2_embedding`**: A 768-dimensional dense vector embedding of the movie's textual information (title, genres, plot summary, director, stars). These embeddings were generated using the `sentence-transformers/all-mpnet-base-v2` model.
*   **`semantic_id`**: A list of 4 discrete integers, representing the Semantic ID (SID) of the movie. These SIDs are generated by the RQ-VAE model, quantizing the `all_mpnet_base_v2_embedding` into a sequence of tokens. Each integer corresponds to a codebook index from one of the RQ-VAE's quantization layers.

## Dataset Creation

This dataset was created through a multi-step process:

1.  **Source Data:** The process began with an enriched MovieLens-32M dataset (`krishnakamath/movielens-32m-movies-enriched`) which already contained detailed plot summaries, director, and star information.
2.  **Embedding Generation:** For each movie, a comprehensive text string was constructed by concatenating its title, genres, plot summary, director, and stars. These strings were then fed into the `sentence-transformers/all-mpnet-base-v2` model to generate 768-dimensional continuous embeddings.
3.  **Semantic ID Generation:** A pre-trained Residual Quantized VAE (RQ-VAE) model (`krishnakamath/rq-vae-movielens`) was used to quantize these continuous embeddings. The RQ-VAE outputs a sequence of discrete tokens (the Semantic IDs), which are then added to the dataset.

The script `create_final_dataset.py` orchestrates this entire process.

## How to Use

This dataset can be easily loaded using the Hugging Face `datasets` library:

```python
from datasets import load_dataset

# Load the dataset
dataset = load_dataset("krishnakamath/movielens-32m-movies-enriched-with-SIDs", split="train")

# Access an example
example = dataset[0]
print(example['title'])
print(example['genres'])
print(example['all_mpnet_base_v2_embedding'][:5]) # Print first 5 dimensions
print(example['semantic_id'])

# You can iterate through the dataset
for movie in dataset.select(range(5)): # Get first 5 movies
    print(f"Title: {movie['title']}, SID: {movie['semantic_id']}")
```

## Potential Use Cases

*   **Semantic Search:** Use the `all_mpnet_base_v2_embedding` for similarity search or the `semantic_id` for discrete, token-based retrieval.
*   **Recommendation Systems:** Incorporate embeddings and SIDs as features for training various recommendation models (e.g., content-based, hybrid).
*   **Clustering and Visualization:** Analyze the distribution of SIDs to understand semantic clusters within the movie catalog.
*   **Interpretable AI:** Explore how discrete SIDs correlate with human-understandable movie attributes.

## Code

The full source code for this project can be found on GitHub: [https://github.com/kykamath/movielens-sids](https://github.com/kykamath/movielens-sids)

## Citation

Please cite the original MovieLens dataset if you use this data in your research:

F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. https://doi.org/10.1145/2827872

## Acknowledgement
The Python scripts used to generate and process this dataset were developed with the assistance of Google's Gemini.
